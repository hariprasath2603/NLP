{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "\n",
    "spaCy is an open-source software library for advanced natural language processing. [Click here](https://spacy.io/api) for API docs. \n",
    "Guides and usage [here](https://spacy.io/usage/linguistic-features)\n",
    "\n",
    "Unlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy steps \n",
    "- Loading language library\n",
    "- Creating pipeline\n",
    "- Tokenization\n",
    "- Tagging parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump tariff VAT threat raises fears of hit to UK\n"
     ]
    }
   ],
   "source": [
    "text = u\"Trump tariff VAT threat raises fears of hit to UK\" # u - denotes unicode\n",
    "doc =  nlp(text)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy Token Properties\n",
    "\n",
    "| Property          | Description                                                                 | Example                                   |\n",
    "|-------------------|-----------------------------------------------------------------------------|-------------------------------------------|\n",
    "| `token.text`      | The raw text of the token.                                                 | `\"Hello\"`                                 |\n",
    "| `token.lemma_`    | The base form of the token (lemmatized form).                              | `\"running\"` → `\"run\"`                     |\n",
    "| `token.pos_`      | The coarse-grained part-of-speech tag.                                     | `\"NOUN\"`, `\"VERB\"`, `\"ADJ\"`               |\n",
    "| `token.tag_`      | The fine-grained part-of-speech tag.                                       | `\"NN\"`, `\"VBZ\"`, `\"JJ\"`                   |\n",
    "| `token.dep_`      | The syntactic dependency label.                                            | `\"nsubj\"`, `\"dobj\"`, `\"punct\"`            |\n",
    "| `token.shape_`    | The shape of the token (e.g., capitalization, punctuation, digits).        | `\"Xxxx\"`, `\"dd\"`, `\"___\"`                 |\n",
    "| `token.is_alpha`  | Whether the token consists of alphabetic characters.                       | `True` for `\"Hello\"`, `False` for `\"123\"` |\n",
    "| `token.is_stop`   | Whether the token is a stop word.                                          | `True` for `\"the\"`, `False` for `\"cat\"`   |\n",
    "| `token.is_punct`  | Whether the token is punctuation.                                          | `True` for `\".\"`, `False` for `\"cat\"`     |\n",
    "| `token.is_digit`  | Whether the token consists of digits.                                      | `True` for `\"123\"`, `False` for `\"cat\"`   |\n",
    "| `token.like_num`  | Whether the token resembles a number (e.g., \"10\", \"ten\").                  | `True` for `\"10\"`, `True` for `\"ten\"`     |\n",
    "| `token.ent_type_`| The named entity type (if the token is part of an entity).                 | `\"PERSON\"`, `\"GPE\"`, `\"DATE\"`             |\n",
    "| `token.ent_iob_`  | The IOB tag of the named entity (Inside, Outside, Beginning).             | `\"B\"`, `\"I\"`, `\"O\"`                       |\n",
    "| `token.sentiment` | The sentiment score of the token (if available).                          | `0.5`, `-0.2`                             |\n",
    "| `token.lang_`     | The language of the token (if available).                                 | `\"en\"`, `\"fr\"`                            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump 100 VERB\n",
      "tariff 92 NOUN\n",
      "VAT 92 NOUN\n",
      "threat 92 NOUN\n",
      "raises 100 VERB\n",
      "fears 92 NOUN\n",
      "of 85 ADP\n",
      "hit 92 NOUN\n",
      "to 85 ADP\n",
      "UK 96 PROPN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos, token.pos_) # pos - parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1394c34d0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1394c3b90>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1394b5e00>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13961be10>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x139619810>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1394b4820>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline # list the current pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Span\n",
    "\n",
    "Truncated version of whole doc. it maintains the relation to to the parent document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of hit\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print(doc[6:8])\n",
    "print(type(doc[6:8])) # here this is not just a string, it is span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is line one.\n",
      "THis is line two.\n",
      "This is line 3\n",
      "--------start------------\n",
      "word on doc2[5] : THis\n",
      "word on doc2[4] : .\n",
      "True\n",
      "False\n",
      "----------End-----------\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "multi_sentence_text = u\"This is line one. THis is line two. This is line 3\"\n",
    "\n",
    "doc2 = nlp(multi_sentence_text)\n",
    "\n",
    "for sentence in doc2.sents:\n",
    "    print(sentence, end=\"\\n\")\n",
    "\n",
    "\n",
    "print(\"--------start------------\")\n",
    "print(\"word on doc2[5] : {}\".format(doc2[5]))\n",
    "print(\"word on doc2[4] : {}\".format(doc2[4]))\n",
    "\n",
    "print(doc2[5].is_sent_start)\n",
    "print(doc2[4].is_sent_start)\n",
    "\n",
    "print(\"----------End-----------\")\n",
    "print(doc2[5].is_sent_end)\n",
    "print(doc2[4].is_sent_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
